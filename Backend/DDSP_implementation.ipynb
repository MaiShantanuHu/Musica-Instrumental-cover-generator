{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7ILFjBt92_fp"
   },
   "outputs": [],
   "source": [
    "!pip install fastapi\n",
    "!pip install colabcode\n",
    "!pip install fastapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x8fFQCKcbP-2"
   },
   "outputs": [],
   "source": [
    "!pip install -qU ddsp==1.6.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jbavFnRf_RDC"
   },
   "outputs": [],
   "source": [
    "# !pip install librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a64idH-3YPMk"
   },
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CO-MQ2uOw_vP"
   },
   "outputs": [],
   "source": [
    "!pip install pyrebase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l671EKsA3TDh"
   },
   "outputs": [],
   "source": [
    "!pip install python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ukp8rZ65WV1K"
   },
   "outputs": [],
   "source": [
    "## !pip install -U \"tensorflow==2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-wJtzXD_ukl"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "\n",
    "import crepe\n",
    "import ddsp\n",
    "import ddsp.training\n",
    "from ddsp.colab.colab_utils import (\n",
    "    auto_tune, get_tuning_factor, download, \n",
    "    play, record, specplot, upload, \n",
    "    DEFAULT_SAMPLE_RATE)\n",
    "from ddsp.training.postprocessing import (\n",
    "    detect_notes, fit_quantile_transform\n",
    ")\n",
    "import gin\n",
    "from google.colab import files\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Helper Functions\n",
    "sample_rate = DEFAULT_SAMPLE_RATE  # 16000\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iNeLf5WH6wdR"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "from colabcode import ColabCode\n",
    "cc = ColabCode(port=8000, code=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KSya1e-Z7wwG"
   },
   "outputs": [],
   "source": [
    "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-OUOjMH9DAN"
   },
   "outputs": [],
   "source": [
    "!ngrok authtoken #enter ngrok authtoken here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TzlGWSYo0fPm"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "from fastapi import FastAPI, Request, Form\n",
    "import shutil\n",
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import pyrebase\n",
    "import librosa\n",
    "import numpy as np\n",
    "import base64\n",
    "import io\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "\n",
    "import ddsp.training\n",
    "from google.colab import files\n",
    "from google.colab import output\n",
    "from IPython import display\n",
    "import note_seq\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "config = {\n",
    "    #add firebase config details here \n",
    "}\n",
    "\n",
    "firebase = pyrebase.initialize_app(config)    \n",
    "storage = firebase.storage()\n",
    "\n",
    "origins = [\n",
    "    \"http://localhost:3000/\",\n",
    "    \"http://localhost:3000\"\n",
    "]\n",
    "\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=origins,\n",
    "    allow_credentials=False,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def read_root():\n",
    "  print(\"Came\")\n",
    "  return \"Hello World\"\n",
    "\n",
    "@app.post(\"/convert\")\n",
    "def upload_file(songfileName: str = Form(...), instrumentType: str = Form(...), uid: str = Form(...)):\n",
    "\n",
    "  # with open(filename, \"wb\") as buffer:\n",
    "  #   shutil.copyfileobj(audio_file.file, buffer)\n",
    "  print(instrumentType)\n",
    "\n",
    "  try:\n",
    "    storage.child(uid + \"/vocals/\" + songfileName).download(songfileName)\n",
    "    \n",
    "    # filenames, audios = upload()\n",
    "    # audio = audios[0]\n",
    "    # if len(audio.shape) == 1:\n",
    "    #   audio = audio[np.newaxis, :]\n",
    "    # print('\\nExtracting audio features...')\n",
    "\n",
    "    DEFAULT_SAMPLE_RATE = ddsp.spectral_ops.CREPE_SAMPLE_RATE\n",
    "    def audio_bytes_to_np(wav_data,\n",
    "                      sample_rate=DEFAULT_SAMPLE_RATE,\n",
    "                      normalize_db=0.1,\n",
    "                      mono=True):\n",
    "      return note_seq.audio_io.wav_data_to_samples_pydub(wav_data=wav_data, sample_rate=sample_rate, normalize_db=normalize_db,num_channels=1 if mono else None)\n",
    "      \n",
    "    with open(songfileName, 'rb') as fd:\n",
    "      data = fd.read()\n",
    "\n",
    "    file_audio = audio_bytes_to_np(data,sample_rate=sample_rate, normalize_db= None)\n",
    "    #print(file_audio)\n",
    "\n",
    "\n",
    "    # #Setup the session.\n",
    "    ddsp.spectral_ops.reset_crepe()\n",
    "\n",
    "\n",
    "    # Compute features.\n",
    "    start_time = time.time()\n",
    "    print(start_time)\n",
    "    #print(\"came here\")\n",
    "    #print(ddsp.training.metrics.compute_audio_features(file_audio))\n",
    "    audio_features = ddsp.training.metrics.compute_audio_features(file_audio)\n",
    "    #print(audio_features)\n",
    "    audio_features['loudness_db'] = audio_features['loudness_db'].astype(np.float32)\n",
    "    audio_features_mod = None\n",
    "    print('Audio features took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "    TRIM = -15\n",
    "    print(\"Hello\")\n",
    "\n",
    "    model =  instrumentType\n",
    "    MODEL = model\n",
    "    def find_model_dir(dir_name):\n",
    "      # Iterate through directories until model directory is found\n",
    "      for root, dirs, filenames in os.walk(dir_name):\n",
    "        for filename in filenames:\n",
    "          if filename.endswith(\".gin\") and not filename.startswith(\".\"):\n",
    "            model_dir = root\n",
    "            break\n",
    "      return model_dir \n",
    "\n",
    "    if model in ('Violin', 'Flute', 'Flute2', 'Trumpet', 'Tenor_Saxophone'):\n",
    "      # Pretrained models.\n",
    "      PRETRAINED_DIR = '/content/pretrained'\n",
    "      # Copy over from gs:// for faster loading.\n",
    "      !rm -r $PRETRAINED_DIR &> /dev/null\n",
    "      !mkdir $PRETRAINED_DIR &> /dev/null\n",
    "      GCS_CKPT_DIR = 'gs://ddsp/models/timbre_transfer_colab/2021-07-08'\n",
    "      model_dir = os.path.join(GCS_CKPT_DIR, 'solo_%s_ckpt' % model.lower())\n",
    "      \n",
    "      !gsutil cp $model_dir/* $PRETRAINED_DIR &> /dev/null\n",
    "      model_dir = PRETRAINED_DIR\n",
    "      gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
    "\n",
    "    else:\n",
    "      # User models.\n",
    "      UPLOAD_DIR = '/content/uploaded'\n",
    "      !mkdir $UPLOAD_DIR\n",
    "      uploaded_files = files.upload()  # check\n",
    "\n",
    "      for fnames in uploaded_files.keys():\n",
    "        print(\"Unzipping... {}\".format(fnames))\n",
    "        !unzip -o \"/content/$fnames\" -d $UPLOAD_DIR &> /dev/null\n",
    "      model_dir = find_model_dir(UPLOAD_DIR)\n",
    "      gin_file = os.path.join(model_dir, 'operative_config-0.gin')\n",
    "\n",
    "\n",
    "    # Load the dataset statistics.\n",
    "    DATASET_STATS = None\n",
    "    dataset_stats_file = os.path.join(model_dir, 'dataset_statistics.pkl')\n",
    "    print(f'Loading dataset statistics from {dataset_stats_file}')\n",
    "    try:\n",
    "      if tf.io.gfile.exists(dataset_stats_file):\n",
    "        with tf.io.gfile.GFile(dataset_stats_file, 'rb') as f:\n",
    "          DATASET_STATS = pickle.load(f)\n",
    "    except Exception as err:\n",
    "      print('Loading dataset statistics from pickle failed: {}.'.format(err))\n",
    "\n",
    "    \n",
    "    # Parse gin config,\n",
    "    with gin.unlock_config():\n",
    "      gin.parse_config_file(gin_file, skip_unknown=True)\n",
    "\n",
    "    # Assumes only one checkpoint in the folder, 'ckpt-[iter]`.\n",
    "    ckpt_files = [f for f in tf.io.gfile.listdir(model_dir) if 'ckpt' in f]\n",
    "    ckpt_name = ckpt_files[0].split('.')[0]\n",
    "    ckpt = os.path.join(model_dir, ckpt_name)\n",
    "\n",
    "    print(\"ckpt files done\")\n",
    "    \n",
    "    # Ensure dimensions and sampling rates are equal\n",
    "    time_steps_train = gin.query_parameter('F0LoudnessPreprocessor.time_steps')\n",
    "    n_samples_train = gin.query_parameter('Harmonic.n_samples')\n",
    "    hop_size = 1000\n",
    "\n",
    "    time_steps = 1000\n",
    "    n_samples = time_steps * hop_size\n",
    "\n",
    "    # print(\"===Trained model===\")\n",
    "    # print(\"Time Steps\", time_steps_train)\n",
    "    # print(\"Samples\", n_samples_train)\n",
    "    # print(\"Hop Size\", hop_size)\n",
    "    # print(\"\\n===Resynthesis===\")\n",
    "    # print(\"Time Steps\", time_steps)\n",
    "    # print(\"Samples\", n_samples)\n",
    "    # print('')\n",
    "\n",
    "    gin_params = [\n",
    "        'Harmonic.n_samples = {}'.format(n_samples),\n",
    "        'FilteredNoise.n_samples = {}'.format(n_samples),\n",
    "        'F0LoudnessPreprocessor.time_steps = {}'.format(time_steps),\n",
    "        'oscillator_bank.use_angular_cumsum = True',  # Avoids cumsum accumulation errors.\n",
    "    ]\n",
    "\n",
    "    with gin.unlock_config():\n",
    "      gin.parse_config(gin_params)\n",
    "\n",
    "\n",
    "    # print(\"Trim all input vectors to correct lengths\") \n",
    "    # for key in ['f0_hz', 'f0_confidence', 'loudness_db']:\n",
    "    #   audio_features[key] = audio_features[key][:time_steps]\n",
    "    # audio_features['audio'] = audio_features['audio'][:, :n_samples]\n",
    "\n",
    "    # print(\"below input vectors\")\n",
    "    # Set up the model just to predict audio given new conditioning\n",
    "    model = ddsp.training.models.Autoencoder()\n",
    "    model.restore(ckpt)\n",
    "\n",
    "    # Build model by running a batch through it.\n",
    "    start_time = time.time()\n",
    "    _ = model(audio_features, training=False)\n",
    "    print('Restoring model took %.1f seconds' % (time.time() - start_time))\n",
    "\n",
    "    threshold = 1\n",
    "    ADJUST = True\n",
    "    quiet = 20\n",
    "    autotune = 0\n",
    "    pitch_shift =  0\n",
    "    loudness_shift = 0\n",
    "\n",
    "    audio_features_mod = {k: v.copy() for k, v in audio_features.items()}\n",
    "\n",
    "\n",
    "    ## Helper functions.\n",
    "    def shift_ld(audio_features, ld_shift=0.0):\n",
    "      \"\"\"Shift loudness by a number of ocatves.\"\"\"\n",
    "      audio_features['loudness_db'] += ld_shift\n",
    "      return audio_features\n",
    "\n",
    "\n",
    "    def shift_f0(audio_features, pitch_shift=0.0):\n",
    "      \"\"\"Shift f0 by a number of ocatves.\"\"\"\n",
    "      audio_features['f0_hz'] *= 2.0 ** (pitch_shift)\n",
    "      audio_features['f0_hz'] = np.clip(audio_features['f0_hz'], \n",
    "                                        0.0, \n",
    "                                        librosa.midi_to_hz(110.0))\n",
    "      return audio_features\n",
    "\n",
    "\n",
    "    mask_on = None\n",
    "\n",
    "    if ADJUST and DATASET_STATS is not None:\n",
    "      # Detect sections that are \"on\".\n",
    "      mask_on, note_on_value = detect_notes(audio_features['loudness_db'],\n",
    "                                            audio_features['f0_confidence'],\n",
    "                                            threshold)\n",
    "\n",
    "      if np.any(mask_on):\n",
    "        # Shift the pitch register.\n",
    "        target_mean_pitch = DATASET_STATS['mean_pitch']\n",
    "        pitch = ddsp.core.hz_to_midi(audio_features['f0_hz'])\n",
    "        mean_pitch = np.mean(pitch[mask_on])\n",
    "        p_diff = target_mean_pitch - mean_pitch\n",
    "        p_diff_octave = p_diff / 12.0\n",
    "        round_fn = np.floor if p_diff_octave > 1.5 else np.ceil\n",
    "        p_diff_octave = round_fn(p_diff_octave)\n",
    "        audio_features_mod = shift_f0(audio_features_mod, p_diff_octave)\n",
    "\n",
    "\n",
    "        # Quantile shift the note_on parts.\n",
    "        _, loudness_norm = fit_quantile_transform(\n",
    "            audio_features['loudness_db'],\n",
    "            mask_on,\n",
    "            inv_quantile=DATASET_STATS['quantile_transform'])\n",
    "\n",
    "        # Turn down the note_off parts.\n",
    "        mask_off = np.logical_not(mask_on)\n",
    "        loudness_norm[mask_off] -=  quiet * (1.0 - note_on_value[mask_off][:, np.newaxis])\n",
    "        loudness_norm = np.reshape(loudness_norm, audio_features['loudness_db'].shape)\n",
    "        \n",
    "        audio_features_mod['loudness_db'] = loudness_norm \n",
    "\n",
    "        # Auto-tune.\n",
    "        if autotune:\n",
    "          f0_midi = np.array(ddsp.core.hz_to_midi(audio_features_mod['f0_hz']))\n",
    "          tuning_factor = get_tuning_factor(f0_midi, audio_features_mod['f0_confidence'], mask_on)\n",
    "          f0_midi_at = auto_tune(f0_midi, tuning_factor, mask_on, amount=autotune)\n",
    "          audio_features_mod['f0_hz'] = ddsp.core.midi_to_hz(f0_midi_at)\n",
    "\n",
    "      else:\n",
    "        print('\\nSkipping auto-adjust (no notes detected or ADJUST box empty).')\n",
    "\n",
    "    else:\n",
    "      print('\\nSkipping auto-adujst (box not checked or no dataset statistics found).')\n",
    "\n",
    "    # Manual Shifts.\n",
    "    audio_features_mod = shift_ld(audio_features_mod, loudness_shift)\n",
    "    audio_features_mod = shift_f0(audio_features_mod, pitch_shift)\n",
    "\n",
    "    af = audio_features if audio_features_mod is None else audio_features_mod\n",
    "\n",
    "    # Run a batch of predictions.\n",
    "    start_time = time.time()\n",
    "    outputs = model(af, training=False)\n",
    "    audio_gen = model.get_audio_from_outputs(outputs)\n",
    "    #print(type(audio_gen))\n",
    "    path = \"outputSongs/\" + songfileName.split(\".\")[0] + \".wav\"\n",
    "    try:\n",
    "      os.makedirs('outputSongs/')\n",
    "    except:\n",
    "      print(\"Not running the os command\")  \n",
    "    #print(path) \n",
    "    sf.write(path, np.ravel(audio_gen), DEFAULT_SAMPLE_RATE, subtype='PCM_24')\n",
    "    print('Prediction took %.1f seconds' % (time.time() - start_time))\n",
    "    storage.child(uid + \"/instrumental/\" + songfileName).put(path)\n",
    "\n",
    "    # Plot\n",
    "    print('Original')\n",
    "    play(file_audio)\n",
    "\n",
    "    print('Resynthesis')\n",
    "    play(audio_gen)\n",
    "    \n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"{e}\")\n",
    "\n",
    "  return \"Success\"\n",
    "\n",
    "# print(storage)\n",
    "# x = storage.child(\"audios/Sunflower.mp3\").download(\"Sunflower.mp3\")\n",
    "# print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 571
    },
    "id": "VJdlEQNg91UP",
    "outputId": "d836917d-811d-4fd0-8033-90dc4e660f95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: NgrokTunnel: \"https://d90b-34-105-53-70.ngrok.io\" -> \"http://localhost:8000\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [74]\n",
      "INFO:uvicorn.error:Started server process [74]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:uvicorn.error:Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:uvicorn.error:Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n",
      "INFO:uvicorn.error:Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Came\n",
      "INFO:     103.134.130.206:0 - \"GET / HTTP/1.1\" 200 OK\n",
      "INFO:     103.134.130.206:0 - \"GET /favicon.ico HTTP/1.1\" 404 Not Found\n",
      "Violin\n",
      "1651857456.213168\n",
      "Audio features took 12.3 seconds\n",
      "Hello\n",
      "Loading dataset statistics from /content/pretrained/dataset_statistics.pkl\n",
      "ckpt files done\n",
      "Restoring model took 3.0 seconds\n",
      "Not running the os command\n",
      "Prediction took 2.6 seconds\n",
      "Original\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"id_3\"> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resynthesis\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"id_4\"> </div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     103.134.130.206:0 - \"POST /convert HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "cc.run_app(app=app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JRO-zKbhOT9"
   },
   "outputs": [],
   "source": [
    "Audio(\"outputSongs/Sunflower.wav\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DDSP_implementation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
